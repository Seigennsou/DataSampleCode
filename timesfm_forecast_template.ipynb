{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 時系列データ予測テンプレート (TimesFM-2.5 Edition)\n",
                "\n",
                "このノートブックは、Googleが開発した時系列基盤モデル **TimesFM-2.5 (Time Series Foundation Model)** を使用した予測テンプレートです。\n",
                "他のテンプレートと同様に、**高度なデータ前処理**、**テキストデータ処理**、**探索的データ分析 (EDA)** の完全なワークフローを含みつつ、予測モデルとしてTimesFMを採用しています。\n",
                "\n",
                "## 特徴\n",
                "- **Zero-Shot Forecasting**: モデルの学習（fit）を行わずに、過去のデータを与えるだけで未来を予測します。\n",
                "- **Foundation Model**: 大規模な事前学習済みモデルを利用し、高い汎化性能を期待できます。\n",
                "- **Comprehensive Workflow**: 欠損値補完やテキスト特徴量の抽出など、実務的な前処理フローを網羅しています。\n",
                "\n",
                "## 目次\n",
                "1. [設定とライブラリのインストール](#1.-設定とライブラリのインストール)\n",
                "2. [データの読み込み](#2.-データの読み込み)\n",
                "3. [データの前処理とクレンジング (Advanced)](#3.-データの前処理とクレンジング-(Advanced))\n",
                "4. [高度なデータ加工 (Comprehensive Pandas & Text)](#4.-高度なデータ加工-(Comprehensive-Pandas-&-Text))\n",
                "5. [探索的データ分析 (EDA)](#5.-探索的データ分析-(EDA))\n",
                "6. [TimesFMモデルの準備](#6.-TimesFMモデルの準備)\n",
                "7. [予測の実行 (Zero-Shot)](#7.-予測の実行-(Zero-Shot))\n",
                "8. [最終評価と結果の保存](#8.-最終評価と結果の保存)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. 設定とライブラリのインストール\n",
                "TimesFMライブラリをインストールし、必要なモジュールをインポートします。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Windows & Python 3.12 workaround: Install timesfm without dependencies to avoid lingvo/paxml errors\n",
                "!pip install timesfm --no-deps\n",
                "!pip install utilsforecast einshape huggingface-hub accelerate jax\n",
                "\n",
                "import os\n",
                "import glob\n",
                "import warnings\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import timesfm\n",
                "import torch # Added for v2.5 API\n",
                "\n",
                "# Scikit-learn modules (for preprocessing)\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.impute import KNNImputer\n",
                "from sklearn.experimental import enable_iterative_imputer\n",
                "from sklearn.impute import IterativeImputer\n",
                "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
                "\n",
                "# 設定\n",
                "warnings.filterwarnings('ignore')\n",
                "pd.set_option('display.max_columns', None)\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "\n",
                "# 乱数シードの固定\n",
                "SEED = 42\n",
                "np.random.seed(SEED)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. データの読み込み\n",
                "ダミーデータを生成して使用します。テキストデータや欠損値を含むリアルなデータセットを模倣します。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_dummy_data():\n",
                "    dates = pd.date_range(start='2023-01-01', end='2024-12-31', freq='D')\n",
                "    n = len(dates)\n",
                "    \n",
                "    # テキストデータのダミー生成\n",
                "    log_messages = [\n",
                "        \"INFO: System Normal\",\n",
                "        \"WARNING: High Latency (120ms)\",\n",
                "        \"ERROR: Connection Failed (Code: 503)\",\n",
                "        \"INFO: Maintenance Started\",\n",
                "        \"INFO: Maintenance Completed\"\n",
                "    ]\n",
                "    \n",
                "    df = pd.DataFrame({\n",
                "        'date': dates,\n",
                "        'unique_id': 'series_1', # TimesFM用のID\n",
                "        'target': np.sin(np.linspace(0, 20, n)) + np.random.normal(0, 0.1, n) + np.linspace(0, 5, n),\n",
                "        'feature_1': np.random.rand(n) * 100,\n",
                "        'feature_2': np.random.randint(0, 10, n),\n",
                "        'feature_missing': np.where(np.random.rand(n) > 0.8, np.nan, np.random.rand(n)),\n",
                "        'category_col': np.random.choice(['A', 'B', 'C'], n),\n",
                "        'log_message': np.random.choice(log_messages, n)\n",
                "    })\n",
                "    return df\n",
                "\n",
                "df = generate_dummy_data()\n",
                "print(f\"Data Shape: {df.shape}\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. データの前処理とクレンジング (Advanced)\n",
                "TimesFMは欠損のない履歴データを期待するため、Iterative Imputerを用いて高度な補完を行います。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "date_col = 'date'\n",
                "if date_col in df.columns:\n",
                "    df[date_col] = pd.to_datetime(df[date_col])\n",
                "    df = df.sort_values(date_col).set_index(date_col)\n",
                "\n",
                "# 数値列の抽出\n",
                "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
                "\n",
                "# Iterative Imputer (多変量回帰による連鎖的な補完)\n",
                "imputer_iter = IterativeImputer(max_iter=10, random_state=SEED)\n",
                "df[numeric_cols] = imputer_iter.fit_transform(df[numeric_cols])\n",
                "\n",
                "# カテゴリ変数のエンコーディング\n",
                "df = pd.get_dummies(df, columns=['category_col'], drop_first=True)\n",
                "\n",
                "print(\"Missing Values After Imputation:\\n\", df.isnull().sum())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. 高度なデータ加工 (Comprehensive Pandas & Text)\n",
                "テキスト処理（Regex, TF-IDF）とPandasによる特徴量作成を行います。\n",
                "※ TimesFM自体は単変量予測（ターゲットのみ使用）が基本ですが、これらの特徴量はデータの理解(EDA)や、将来的に共変量として使用する場合に有用です。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Text Data Processing ---\n",
                "\n",
                "# 1. 正規表現 (Regex) による抽出\n",
                "df['error_code'] = df['log_message'].str.extract(r'Code: (\\d+)').fillna(0).astype(int)\n",
                "\n",
                "# 2. 文字列操作とフラグ作成\n",
                "df['is_error'] = df['log_message'].str.contains('ERROR', case=False).astype(int)\n",
                "\n",
                "# 3. テキストのクリーニング\n",
                "df['clean_message'] = df['log_message'].str.lower().str.strip()\n",
                "\n",
                "# 4. TF-IDF Vectorization\n",
                "tfidf = TfidfVectorizer(max_features=5, stop_words='english')\n",
                "tfidf_df = pd.DataFrame(tfidf.fit_transform(df['clean_message']).toarray(), \n",
                "                        columns=[f'tfidf_{i}' for i in range(5)], index=df.index)\n",
                "df = pd.concat([df, tfidf_df], axis=1)\n",
                "df.drop(columns=['log_message', 'clean_message'], inplace=True)\n",
                "\n",
                "# --- Pandas Advanced Processing ---\n",
                "\n",
                "# 5. Rolling & EWMA\n",
                "df['rolling_mean_7d'] = df['target'].rolling('7D').mean()\n",
                "df['ewm_mean_span7'] = df['target'].ewm(span=7).mean()\n",
                "\n",
                "# 6. Differencing\n",
                "df['target_diff'] = df['target'].diff()\n",
                "\n",
                "# 7. Expanding\n",
                "df['expanding_max'] = df['target'].expanding().max()\n",
                "\n",
                "df.dropna(inplace=True)\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. 探索的データ分析 (EDA)\n",
                "データの傾向を可視化します。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(15, 5))\n",
                "plt.plot(df.index, df['target'], label='Target')\n",
                "plt.plot(df.index, df['ewm_mean_span7'], label='EWMA (Span 7)', linestyle='--', alpha=0.8)\n",
                "plt.title('Time Series Plot with EWMA')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. TimesFMモデルの準備 (v2.5 API)\n",
                "Hugging Faceからチェックポイント (`google/timesfm-2.5-200m-pytorch`) をロードし、コンパイルします。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# GPUが使える場合は設定 (ここではCPU/GPU自動判定の例として記述しますが、基本はCPUでも動作します)\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "# float32の精度設定 (推奨)\n",
                "torch.set_float32_matmul_precision(\"high\")\n",
                "\n",
                "# モデルのロード (PyTorch backend)\n",
                "# 200Mパラメータモデルを使用\n",
                "model = timesfm.TimesFM_2p5_200M_torch.from_pretrained(\"google/timesfm-2.5-200m-pytorch\")\n",
                "\n",
                "# モデルのコンパイル (設定)\n",
                "model.compile(\n",
                "    timesfm.ForecastConfig(\n",
                "        max_context=1024,       # 入力系列の最大長\n",
                "        max_horizon=30,         # 予測ホライゾン (30日)\n",
                "        normalize_inputs=True,  # 入力の正規化\n",
                "        use_continuous_quantile_head=True, # 量子化ヘッドの使用\n",
                "        force_flip_invariance=True,\n",
                "        infer_is_positive=True,\n",
                "        fix_quantile_crossing=True,\n",
                "    )\n",
                ")\n",
                "\n",
                "print(\"TimesFM-2.5 Model Loaded and Compiled Successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. 予測の実行 (Zero-Shot)\n",
                "学習データを与えて、未来の予測を行います。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# データの準備\n",
                "# TimesFM v2.5の forecast メソッドは numpy array のリストを入力として受け取ります\n",
                "# (Batch size x Context length)\n",
                "\n",
                "# 訓練データ (過去データ) の準備\n",
                "# 最後の30日をテスト用として除外し、それ以前をコンテキストとして使用\n",
                "train_values = df['target'].iloc[:-30].values\n",
                "test_values = df['target'].iloc[-30:].values\n",
                "test_dates = df.index[-30:]\n",
                "\n",
                "# 入力はリスト形式 (複数の時系列を同時に予測可能ですが、今回は1つ)\n",
                "inputs = [train_values]\n",
                "\n",
                "# 予測の実行\n",
                "print(f\"Forecasting for horizon: 30...\")\n",
                "point_forecast, quantile_forecast = model.forecast(\n",
                "    horizon=30,\n",
                "    inputs=inputs,\n",
                ")\n",
                "\n",
                "# 結果の確認\n",
                "# point_forecast shape: (batch_size, horizon) -> (1, 30)\n",
                "# quantile_forecast shape: (batch_size, horizon, quantiles) -> (1, 30, 10) (mean + 9 quantiles)\n",
                "\n",
                "print(\"Point Forecast Shape:\", point_forecast.shape)\n",
                "\n",
                "# 結果をDataFrameに整形\n",
                "pred_values = point_forecast[0] # 最初のバッチ(今回は1つだけ)を取り出す\n",
                "forecast_df = pd.DataFrame({\n",
                "    'date': test_dates,\n",
                "    'timesfm_pred': pred_values\n",
                "}).set_index('date')\n",
                "\n",
                "forecast_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. 最終評価と結果の保存\n",
                "実測値と予測値を比較し、評価指標を算出・保存します。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 可視化\n",
                "plt.figure(figsize=(15, 6))\n",
                "plt.plot(df.index[-60:], df['target'].iloc[-60:], label='Actual (History + Test)', color='blue', alpha=0.5)\n",
                "plt.plot(forecast_df.index, forecast_df['timesfm_pred'], label='TimesFM Forecast', color='red', linestyle='--')\n",
                "plt.axvline(x=df.index[-31], color='gray', linestyle=':', label='Forecast Start')\n",
                "plt.title('TimesFM-2.5 Zero-Shot Forecasting')\n",
                "plt.legend()\n",
                "plt.show()\n",
                "\n",
                "# 評価\n",
                "rmse = np.sqrt(mean_squared_error(test_values, forecast_df['timesfm_pred']))\n",
                "mae = mean_absolute_error(test_values, forecast_df['timesfm_pred'])\n",
                "\n",
                "print(f\"Test RMSE: {rmse:.4f}\")\n",
                "print(f\"Test MAE: {mae:.4f}\")\n",
                "\n",
                "# 保存\n",
                "results_df = pd.DataFrame({'Actual': test_values, 'Predicted': forecast_df['timesfm_pred'].values}, index=test_dates)\n",
                "results_df.to_csv('timesfm_forecast_results.csv')\n",
                "print(\"Saved to timesfm_forecast_results.csv\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}